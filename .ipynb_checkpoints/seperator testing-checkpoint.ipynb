{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "from gensim import models\n",
    "from multiprocessing import Pool as P\n",
    "import time\n",
    "import datetime\n",
    "from math import floor\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting directories\n",
    "data_dir = '../master_thesis_data/weibo_deduplicated'\n",
    "dates_name, texts_name = 'weibo_all_dates.pickle', 'weibo_all_texts_new.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading in data\n",
    "with open(os.path.join(data_dir, texts_name), 'rb') as handle:\n",
    "    texts = pickle.load(handle)\n",
    "with open(os.path.join(data_dir, dates_name), 'rb') as handle:\n",
    "    dates = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_list = jieba.cut(texts[0], cut_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_line = ' '.join(seg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'发现 我 的 微 博会 自动 取消 关注 , , , 也 是 醉 了 , , , 您 这么 自说自话 地 取消 真的 好 吗 ？ 问过 我 吗 ？ 我 很 怕 的 你 知道 吗 ？ 【 本周 刚 和 人 探讨 过 人工智能 的 觉醒 】'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'发现 我 的 微 博会 自动 取消 关注 也 是 醉 了 您 这么 自说自话 地 取消 真的 好 吗 问过 我 吗 我 很 怕 的 你 知道 吗 本周 刚 和 人 探讨 过 人工智能 的 觉醒 '"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_line = re.sub(r'\\W+', ' ', sample_line)\n",
    "sample_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['发现',\n",
       " '我',\n",
       " '的',\n",
       " '微',\n",
       " '博会',\n",
       " '自动',\n",
       " '取消',\n",
       " '关注',\n",
       " '也',\n",
       " '是',\n",
       " '醉',\n",
       " '了',\n",
       " '您',\n",
       " '这么',\n",
       " '自说自话',\n",
       " '地',\n",
       " '取消',\n",
       " '真的',\n",
       " '好',\n",
       " '吗',\n",
       " '问过',\n",
       " '我',\n",
       " '吗',\n",
       " '我',\n",
       " '很',\n",
       " '怕',\n",
       " '的',\n",
       " '你',\n",
       " '知道',\n",
       " '吗',\n",
       " '本周',\n",
       " '刚',\n",
       " '和',\n",
       " '人',\n",
       " '探讨',\n",
       " '过',\n",
       " '人工智能',\n",
       " '的',\n",
       " '觉醒',\n",
       " '']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_line.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'weibo_all_texts_new.pickle'), 'rb') as handle:\n",
    "    texts = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count() - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Word2Vec(min_count=5,\n",
    "                       window = 10,\n",
    "                       size = 3000,\n",
    "                       sample = 6e-5,\n",
    "                       alpha = 0.03,\n",
    "                       min_alpha = 0.0007,\n",
    "                       negative = 50,\n",
    "                       workers = cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(texts[:10000], progress_per = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin = time.time()\n",
    "model.train(texts[:10000], total_examples=model.corpus_count, epochs=30, report_delay=1)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.65111419359843"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(end - begin)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('的', 0.5325926542282104),\n",
       " ('', 0.5124344825744629),\n",
       " ('O', 0.4849620461463928),\n",
       " ('AI', 0.44319653511047363),\n",
       " ('未来', 0.42329198122024536),\n",
       " ('技术', 0.4019441604614258),\n",
       " ('和', 0.36998993158340454),\n",
       " ('发展', 0.36974191665649414),\n",
       " ('机器人', 0.3674817681312561),\n",
       " ('机器', 0.35526013374328613),\n",
       " ('网页', 0.35511350631713867),\n",
       " ('链接', 0.34447500109672546),\n",
       " ('科技', 0.3357526659965515),\n",
       " ('skymind', 0.33529406785964966),\n",
       " ('智能', 0.33263707160949707),\n",
       " ('了', 0.32909056544303894),\n",
       " ('是', 0.3266730308532715),\n",
       " ('时代', 0.32044821977615356),\n",
       " ('如何', 0.3176739513874054),\n",
       " ('将', 0.310677170753479)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive = ['人工智能'], topn = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let's see how we can partition the data for continous training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_date = '2016-4-17'\n",
    "begin_date = datetime.datetime.strptime(begin_date, '%Y-%m-%d')\n",
    "window_size = int(356/12*6)\n",
    "slider_step = int(356/12*3)\n",
    "d_upper_limit = datetime.datetime.strptime('2019-4-17', '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = begin_date + datetime.timedelta(days = window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.datetime(2016, 4, 17, 0, 0), datetime.datetime(2016, 10, 12, 0, 0))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "begin_date, end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_texts = [text for i, text in enumerate(texts) if begin_date <= dates[i] <= end_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2016, 5, 17, 0, 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "begin_date + datetime.timedelta(days = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = floor(((d_upper_limit - begin_date).days - slider_step)/slider_step) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0\n",
      "begin date is 2016-04-17 00:00:00\n",
      "end date is 2016-10-12 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter 4\n",
      "begin date is 2017-04-08 00:00:00\n",
      "end date is 2017-10-03 00:00:00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-adb77b027f27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# getting the corresponding texts based on date range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0msub_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtexts\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msub_begin_date\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mdates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0msub_end_date\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_texts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-adb77b027f27>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# getting the corresponding texts based on date range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0msub_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtexts\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msub_begin_date\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mdates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0msub_end_date\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_texts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "\n",
    "# placeholder for the top n keywords\n",
    "li_top_n = []\n",
    "\n",
    "# iterate through for continous execution\n",
    "for i in range(n_iter):\n",
    "    print('iter {}'.format(i))\n",
    "    # determining the sub period limits\n",
    "    sub_begin_date = begin_date + datetime.timedelta(days = i * slider_step)\n",
    "    print('begin date is {}'.format(sub_begin_date))\n",
    "    sub_end_date = sub_begin_date + datetime.timedelta(days = window_size)\n",
    "    print('end date is {}'.format(sub_end_date))\n",
    "    \n",
    "    # getting the corresponding texts based on date range\n",
    "    sub_texts = [texts for i, text in enumerate(texts) if sub_begin_date <= dates[i] <= sub_end_date]\n",
    "    print(sub_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # initiate the model\n",
    "    model = models.Word2Vec(min_count=3,\n",
    "                       window = 10,\n",
    "                       size = 3000,\n",
    "                       sample = 6e-5,\n",
    "                       alpha = 0.03,\n",
    "                       min_alpha = 0.0007,\n",
    "                       negative = 80,\n",
    "                       workers = cores)\n",
    "    \n",
    "    # build vocab\n",
    "    model.build_vocab(sub_texts)\n",
    "    # train\n",
    "    model.train(sub_texts, total_examples=model.corpus_count, epochs=50, report_delay=1)\n",
    "    # getting the top keywords\n",
    "    top_n = model.wv.most_similar(positive = ['人工智能'], topn = 50)\n",
    "    li_top_n.append(top_n)\n",
    "    # get time lapsed\n",
    "    time_lapsed = time.time() - begin\n",
    "    print('iteration {} complete, time lapsed: {}'.format(i, round(time_lapsed/60, 2)))\n",
    "    print('time remaining is estimated to be {}'.format(round(((n_iter - i - 1)*time_lapsed/(i + 1))/60), 2))\n",
    "\n",
    "# saving\n",
    "with open(os.path.join(data_dir, 'top_n_list.pickle'), 'wb') as handle:\n",
    "    pickle.dump(li_top_n, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
