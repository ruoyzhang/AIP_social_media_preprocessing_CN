{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "from gensim import models\n",
    "import multiprocessing\n",
    "import time\n",
    "import datetime\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting directories\n",
    "data_dir = '../master_thesis_data/weibo_deduplicated'\n",
    "dates_name, texts_name = 'weibo_all_dates.pickle', 'weibo_all_texts_new.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-e903be9522f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# loading in data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdates_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# loading in data\n",
    "with open(os.path.join(data_dir, texts_name), 'rb') as handle:\n",
    "    texts = pickle.load(handle)\n",
    "with open(os.path.join(data_dir, dates_name), 'rb') as handle:\n",
    "    dates = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_list = jieba.cut(texts[0], cut_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_line = ' '.join(seg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'发现 我 的 微 博会 自动 取消 关注 , , , 也 是 醉 了 , , , 您 这么 自说自话 地 取消 真的 好 吗 ？ 问过 我 吗 ？ 我 很 怕 的 你 知道 吗 ？ 【 本周 刚 和 人 探讨 过 人工智能 的 觉醒 】'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'发现 我 的 微 博会 自动 取消 关注 也 是 醉 了 您 这么 自说自话 地 取消 真的 好 吗 问过 我 吗 我 很 怕 的 你 知道 吗 本周 刚 和 人 探讨 过 人工智能 的 觉醒 '"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_line = re.sub(r'\\W+', ' ', sample_line)\n",
    "sample_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['发现',\n",
       " '我',\n",
       " '的',\n",
       " '微',\n",
       " '博会',\n",
       " '自动',\n",
       " '取消',\n",
       " '关注',\n",
       " '也',\n",
       " '是',\n",
       " '醉',\n",
       " '了',\n",
       " '您',\n",
       " '这么',\n",
       " '自说自话',\n",
       " '地',\n",
       " '取消',\n",
       " '真的',\n",
       " '好',\n",
       " '吗',\n",
       " '问过',\n",
       " '我',\n",
       " '吗',\n",
       " '我',\n",
       " '很',\n",
       " '怕',\n",
       " '的',\n",
       " '你',\n",
       " '知道',\n",
       " '吗',\n",
       " '本周',\n",
       " '刚',\n",
       " '和',\n",
       " '人',\n",
       " '探讨',\n",
       " '过',\n",
       " '人工智能',\n",
       " '的',\n",
       " '觉醒',\n",
       " '']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_line.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'weibo_all_texts_new.pickle'), 'rb') as handle:\n",
    "    texts = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count() - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Word2Vec(min_count=5,\n",
    "                       window = 10,\n",
    "                       size = 3000,\n",
    "                       sample = 6e-5,\n",
    "                       alpha = 0.03,\n",
    "                       min_alpha = 0.0007,\n",
    "                       negative = 50,\n",
    "                       workers = cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(texts[:100000], progress_per = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin = time.time()\n",
    "model.train(texts[:100000], total_examples=model.corpus_count, epochs=30, report_delay=1)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.65111419359843"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(end - begin)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('的', 0.5325926542282104),\n",
       " ('', 0.5124344825744629),\n",
       " ('O', 0.4849620461463928),\n",
       " ('AI', 0.44319653511047363),\n",
       " ('未来', 0.42329198122024536),\n",
       " ('技术', 0.4019441604614258),\n",
       " ('和', 0.36998993158340454),\n",
       " ('发展', 0.36974191665649414),\n",
       " ('机器人', 0.3674817681312561),\n",
       " ('机器', 0.35526013374328613),\n",
       " ('网页', 0.35511350631713867),\n",
       " ('链接', 0.34447500109672546),\n",
       " ('科技', 0.3357526659965515),\n",
       " ('skymind', 0.33529406785964966),\n",
       " ('智能', 0.33263707160949707),\n",
       " ('了', 0.32909056544303894),\n",
       " ('是', 0.3266730308532715),\n",
       " ('时代', 0.32044821977615356),\n",
       " ('如何', 0.3176739513874054),\n",
       " ('将', 0.310677170753479)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive = ['人工智能'], topn = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let's see how we can partition the data for continous training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_date = '2016-4-17'\n",
    "begin_date = datetime.datetime.strptime(begin_date, '%Y-%m-%d')\n",
    "window_size = int(356/12*6)\n",
    "slider_step = int(356/12*3)\n",
    "d_upper_limit = datetime.datetime.strptime('2019-4-17', '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = begin_date + datetime.timedelta(days = window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.datetime(2016, 4, 17, 0, 0), datetime.datetime(2016, 10, 12, 0, 0))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "begin_date, end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2016, 5, 17, 0, 0)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "begin_date + datetime.timedelta(days = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = floor(((d_upper_limit - begin_date).days - slider_step)/slider_step) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# iterate through for continous execution\n",
    "for i in range(n_iter):\n",
    "    # determining the sub period limits\n",
    "    begin_date = begin_date + datetime.timedelta(days = i * slider_step)\n",
    "    end_date = begin_date + datetime.timedelta(days = i * window_size)\n",
    "    \n",
    "    # getting the indices for the correct texts based on date range\n",
    "    indx = [i for i, date in enumerate(dates) if begin_date <= date <= end_date]\n",
    "    \n",
    "    # getting the corresponding texts\n",
    "    sub_texts = [text for i, text in enumerate(texts) if i in indx]\n",
    "    \n",
    "    print(len(texts))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
